{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Anuradha\\anaconda3\\Scripts\\envs\\DevAI\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Starting the training process...\n",
      "Downloading and loading tone dataset...\n",
      "Initializing Tone Analyzer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting tone fine-tuning process...\n",
      "Preparing training dataset...\n",
      "Splitting into train/validation sets...\n",
      "Setting up training arguments...\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anuradha\\anaconda3\\Scripts\\envs\\DevAI\\Lib\\site-packages\\transformers\\training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e36ee993105498c87f69236bbf21254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6067, 'grad_norm': 4.705992698669434, 'learning_rate': 4.0000000000000003e-07, 'epoch': 0.08}\n",
      "{'loss': 1.6116, 'grad_norm': 3.6831698417663574, 'learning_rate': 8.000000000000001e-07, 'epoch': 0.17}\n",
      "{'loss': 1.6042, 'grad_norm': 5.108077049255371, 'learning_rate': 1.2000000000000002e-06, 'epoch': 0.25}\n",
      "{'loss': 1.6087, 'grad_norm': 3.2815654277801514, 'learning_rate': 1.6000000000000001e-06, 'epoch': 0.33}\n",
      "{'loss': 1.6242, 'grad_norm': 3.5876388549804688, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.42}\n",
      "{'loss': 1.5908, 'grad_norm': 3.1172780990600586, 'learning_rate': 2.4000000000000003e-06, 'epoch': 0.5}\n",
      "{'loss': 1.5924, 'grad_norm': 4.031172275543213, 'learning_rate': 2.8000000000000003e-06, 'epoch': 0.58}\n",
      "{'loss': 1.5985, 'grad_norm': 4.316586494445801, 'learning_rate': 3.2000000000000003e-06, 'epoch': 0.67}\n",
      "{'loss': 1.5883, 'grad_norm': 3.533423900604248, 'learning_rate': 3.6000000000000003e-06, 'epoch': 0.75}\n",
      "{'loss': 1.5832, 'grad_norm': 2.4801716804504395, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.83}\n",
      "{'loss': 1.5545, 'grad_norm': 3.914041757583618, 'learning_rate': 4.4e-06, 'epoch': 0.92}\n",
      "{'loss': 1.5926, 'grad_norm': 7.120569229125977, 'learning_rate': 4.800000000000001e-06, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7671242b7e9e4dadae2b0bc681fef8e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5753663778305054, 'eval_runtime': 368.7418, 'eval_samples_per_second': 1.296, 'eval_steps_per_second': 0.081, 'epoch': 1.0}\n",
      "{'train_runtime': 7292.707, 'train_samples_per_second': 0.262, 'train_steps_per_second': 0.016, 'train_loss': 1.5963021914164226, 'epoch': 1.0}\n",
      "Saving fine-tuned model...\n",
      "Fine-tuning complete!\n",
      "Initializing Sentiment Analyzer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting sentiment fine-tuning process...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anuradha\\anaconda3\\Scripts\\envs\\DevAI\\Lib\\site-packages\\transformers\\training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cd15deb51474a338a881d309eed2808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9675, 'grad_norm': 7.191839218139648, 'learning_rate': 2.0000000000000002e-07, 'epoch': 0.01}\n",
      "{'loss': 0.9703, 'grad_norm': 6.925292015075684, 'learning_rate': 4.0000000000000003e-07, 'epoch': 0.01}\n",
      "{'loss': 0.9807, 'grad_norm': 5.493546009063721, 'learning_rate': 6.000000000000001e-07, 'epoch': 0.02}\n",
      "{'loss': 0.9541, 'grad_norm': 9.554792404174805, 'learning_rate': 8.000000000000001e-07, 'epoch': 0.03}\n",
      "{'loss': 0.935, 'grad_norm': 7.233910083770752, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.03}\n",
      "{'loss': 0.9242, 'grad_norm': 4.8051371574401855, 'learning_rate': 1.2000000000000002e-06, 'epoch': 0.04}\n",
      "{'loss': 0.8791, 'grad_norm': 7.0243000984191895, 'learning_rate': 1.4000000000000001e-06, 'epoch': 0.04}\n",
      "{'loss': 0.8502, 'grad_norm': 6.498027324676514, 'learning_rate': 1.6000000000000001e-06, 'epoch': 0.05}\n",
      "{'loss': 0.8381, 'grad_norm': 5.533255577087402, 'learning_rate': 1.8000000000000001e-06, 'epoch': 0.06}\n",
      "{'loss': 0.8187, 'grad_norm': 7.102581024169922, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.06}\n",
      "{'loss': 0.8063, 'grad_norm': 6.731174468994141, 'learning_rate': 2.2e-06, 'epoch': 0.07}\n",
      "{'loss': 0.7701, 'grad_norm': 7.102377414703369, 'learning_rate': 2.4000000000000003e-06, 'epoch': 0.08}\n",
      "{'loss': 0.698, 'grad_norm': 5.510140419006348, 'learning_rate': 2.6e-06, 'epoch': 0.08}\n",
      "{'loss': 0.7193, 'grad_norm': 5.482964515686035, 'learning_rate': 2.8000000000000003e-06, 'epoch': 0.09}\n",
      "{'loss': 0.7121, 'grad_norm': 4.924602031707764, 'learning_rate': 3e-06, 'epoch': 0.1}\n",
      "{'loss': 0.6609, 'grad_norm': 4.543708801269531, 'learning_rate': 3.2000000000000003e-06, 'epoch': 0.1}\n",
      "{'loss': 0.6404, 'grad_norm': 6.389552116394043, 'learning_rate': 3.4000000000000005e-06, 'epoch': 0.11}\n",
      "{'loss': 0.5954, 'grad_norm': 8.742547035217285, 'learning_rate': 3.6000000000000003e-06, 'epoch': 0.12}\n",
      "{'loss': 0.5929, 'grad_norm': 6.333696365356445, 'learning_rate': 3.8000000000000005e-06, 'epoch': 0.12}\n",
      "{'loss': 0.5633, 'grad_norm': 6.89414644241333, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.13}\n",
      "{'loss': 0.5325, 'grad_norm': 6.674108028411865, 'learning_rate': 4.2000000000000004e-06, 'epoch': 0.13}\n",
      "{'loss': 0.4979, 'grad_norm': 8.00767707824707, 'learning_rate': 4.4e-06, 'epoch': 0.14}\n",
      "{'loss': 0.4603, 'grad_norm': 9.116719245910645, 'learning_rate': 4.600000000000001e-06, 'epoch': 0.15}\n",
      "{'loss': 0.4652, 'grad_norm': 13.338871955871582, 'learning_rate': 4.800000000000001e-06, 'epoch': 0.15}\n",
      "{'loss': 0.4716, 'grad_norm': 11.796756744384766, 'learning_rate': 5e-06, 'epoch': 0.16}\n",
      "{'loss': 0.5191, 'grad_norm': 18.432756423950195, 'learning_rate': 5.2e-06, 'epoch': 0.17}\n",
      "{'loss': 0.4028, 'grad_norm': 12.260732650756836, 'learning_rate': 5.400000000000001e-06, 'epoch': 0.17}\n",
      "{'loss': 0.3738, 'grad_norm': 6.092956066131592, 'learning_rate': 5.600000000000001e-06, 'epoch': 0.18}\n",
      "{'loss': 0.3724, 'grad_norm': 6.43867301940918, 'learning_rate': 5.8e-06, 'epoch': 0.19}\n",
      "{'loss': 0.3287, 'grad_norm': 24.094947814941406, 'learning_rate': 6e-06, 'epoch': 0.19}\n",
      "{'loss': 0.3416, 'grad_norm': 8.7965669631958, 'learning_rate': 6.200000000000001e-06, 'epoch': 0.2}\n",
      "{'loss': 0.3689, 'grad_norm': 10.610616683959961, 'learning_rate': 6.4000000000000006e-06, 'epoch': 0.2}\n",
      "{'loss': 0.2921, 'grad_norm': 6.7651166915893555, 'learning_rate': 6.600000000000001e-06, 'epoch': 0.21}\n",
      "{'loss': 0.3044, 'grad_norm': 3.799323797225952, 'learning_rate': 6.800000000000001e-06, 'epoch': 0.22}\n",
      "{'loss': 0.321, 'grad_norm': 7.127208232879639, 'learning_rate': 7e-06, 'epoch': 0.22}\n",
      "{'loss': 0.2785, 'grad_norm': 21.57372283935547, 'learning_rate': 7.2000000000000005e-06, 'epoch': 0.23}\n",
      "{'loss': 0.3038, 'grad_norm': 9.619056701660156, 'learning_rate': 7.4e-06, 'epoch': 0.24}\n",
      "{'loss': 0.2213, 'grad_norm': 4.345658779144287, 'learning_rate': 7.600000000000001e-06, 'epoch': 0.24}\n",
      "{'loss': 0.2836, 'grad_norm': 8.624212265014648, 'learning_rate': 7.800000000000002e-06, 'epoch': 0.25}\n",
      "{'loss': 0.3037, 'grad_norm': 13.557801246643066, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.26}\n",
      "{'loss': 0.3381, 'grad_norm': 5.168766021728516, 'learning_rate': 8.2e-06, 'epoch': 0.26}\n",
      "{'loss': 0.3331, 'grad_norm': 35.390567779541016, 'learning_rate': 8.400000000000001e-06, 'epoch': 0.27}\n",
      "{'loss': 0.1875, 'grad_norm': 12.017768859863281, 'learning_rate': 8.6e-06, 'epoch': 0.28}\n",
      "{'loss': 0.296, 'grad_norm': 20.44297218322754, 'learning_rate': 8.8e-06, 'epoch': 0.28}\n",
      "{'loss': 0.3581, 'grad_norm': 2.1396782398223877, 'learning_rate': 9e-06, 'epoch': 0.29}\n",
      "{'loss': 0.3573, 'grad_norm': 22.2569637298584, 'learning_rate': 9.200000000000002e-06, 'epoch': 0.29}\n",
      "{'loss': 0.2096, 'grad_norm': 7.658514976501465, 'learning_rate': 9.4e-06, 'epoch': 0.3}\n",
      "{'loss': 0.3087, 'grad_norm': 6.248586654663086, 'learning_rate': 9.600000000000001e-06, 'epoch': 0.31}\n",
      "{'loss': 0.3283, 'grad_norm': 6.945347309112549, 'learning_rate': 9.800000000000001e-06, 'epoch': 0.31}\n",
      "{'loss': 0.2901, 'grad_norm': 13.14568042755127, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 0.2814, 'grad_norm': 9.181396484375, 'learning_rate': 9.905926622765757e-06, 'epoch': 0.33}\n",
      "{'loss': 0.2226, 'grad_norm': 8.23550796508789, 'learning_rate': 9.811853245531515e-06, 'epoch': 0.33}\n",
      "{'loss': 0.2208, 'grad_norm': 12.7311372756958, 'learning_rate': 9.717779868297272e-06, 'epoch': 0.34}\n",
      "{'loss': 0.3005, 'grad_norm': 20.124820709228516, 'learning_rate': 9.62370649106303e-06, 'epoch': 0.35}\n",
      "{'loss': 0.2872, 'grad_norm': 9.712510108947754, 'learning_rate': 9.529633113828787e-06, 'epoch': 0.35}\n",
      "{'loss': 0.2411, 'grad_norm': 10.677505493164062, 'learning_rate': 9.435559736594545e-06, 'epoch': 0.36}\n",
      "{'loss': 0.2186, 'grad_norm': 12.788507461547852, 'learning_rate': 9.341486359360303e-06, 'epoch': 0.36}\n",
      "{'loss': 0.2341, 'grad_norm': 14.222306251525879, 'learning_rate': 9.24741298212606e-06, 'epoch': 0.37}\n",
      "{'loss': 0.3685, 'grad_norm': 7.258698463439941, 'learning_rate': 9.153339604891816e-06, 'epoch': 0.38}\n",
      "{'loss': 0.3014, 'grad_norm': 6.463247776031494, 'learning_rate': 9.059266227657574e-06, 'epoch': 0.38}\n",
      "{'loss': 0.3339, 'grad_norm': 12.888259887695312, 'learning_rate': 8.96519285042333e-06, 'epoch': 0.39}\n",
      "{'loss': 0.2598, 'grad_norm': 16.01784896850586, 'learning_rate': 8.871119473189089e-06, 'epoch': 0.4}\n",
      "{'loss': 0.2357, 'grad_norm': 11.870479583740234, 'learning_rate': 8.777046095954845e-06, 'epoch': 0.4}\n",
      "{'loss': 0.2461, 'grad_norm': 5.637299060821533, 'learning_rate': 8.682972718720603e-06, 'epoch': 0.41}\n",
      "{'loss': 0.3157, 'grad_norm': 9.652387619018555, 'learning_rate': 8.58889934148636e-06, 'epoch': 0.42}\n",
      "{'loss': 0.2888, 'grad_norm': 13.35327434539795, 'learning_rate': 8.494825964252116e-06, 'epoch': 0.42}\n",
      "{'loss': 0.2392, 'grad_norm': 10.102872848510742, 'learning_rate': 8.400752587017874e-06, 'epoch': 0.43}\n",
      "{'loss': 0.203, 'grad_norm': 7.185054302215576, 'learning_rate': 8.306679209783632e-06, 'epoch': 0.44}\n",
      "{'loss': 0.2827, 'grad_norm': 8.651641845703125, 'learning_rate': 8.212605832549389e-06, 'epoch': 0.44}\n",
      "{'loss': 0.274, 'grad_norm': 12.409745216369629, 'learning_rate': 8.118532455315147e-06, 'epoch': 0.45}\n",
      "{'loss': 0.2763, 'grad_norm': 9.026753425598145, 'learning_rate': 8.024459078080903e-06, 'epoch': 0.45}\n",
      "{'loss': 0.1852, 'grad_norm': 11.294275283813477, 'learning_rate': 7.930385700846662e-06, 'epoch': 0.46}\n",
      "{'loss': 0.3026, 'grad_norm': 27.425790786743164, 'learning_rate': 7.836312323612418e-06, 'epoch': 0.47}\n",
      "{'loss': 0.1993, 'grad_norm': 1.9013243913650513, 'learning_rate': 7.742238946378176e-06, 'epoch': 0.47}\n",
      "{'loss': 0.2592, 'grad_norm': 9.074178695678711, 'learning_rate': 7.648165569143933e-06, 'epoch': 0.48}\n",
      "{'loss': 0.1875, 'grad_norm': 12.73573112487793, 'learning_rate': 7.55409219190969e-06, 'epoch': 0.49}\n",
      "{'loss': 0.2164, 'grad_norm': 2.2591922283172607, 'learning_rate': 7.460018814675447e-06, 'epoch': 0.49}\n",
      "{'loss': 0.296, 'grad_norm': 10.138946533203125, 'learning_rate': 7.365945437441205e-06, 'epoch': 0.5}\n",
      "{'loss': 0.1915, 'grad_norm': 7.574965953826904, 'learning_rate': 7.271872060206963e-06, 'epoch': 0.51}\n",
      "{'loss': 0.215, 'grad_norm': 1.7876406908035278, 'learning_rate': 7.17779868297272e-06, 'epoch': 0.51}\n",
      "{'loss': 0.2293, 'grad_norm': 12.79188060760498, 'learning_rate': 7.083725305738477e-06, 'epoch': 0.52}\n",
      "{'loss': 0.2818, 'grad_norm': 13.71525764465332, 'learning_rate': 6.989651928504234e-06, 'epoch': 0.52}\n",
      "{'loss': 0.1889, 'grad_norm': 4.671924591064453, 'learning_rate': 6.895578551269991e-06, 'epoch': 0.53}\n",
      "{'loss': 0.2348, 'grad_norm': 3.6247856616973877, 'learning_rate': 6.8015051740357485e-06, 'epoch': 0.54}\n",
      "{'loss': 0.3999, 'grad_norm': 31.1181697845459, 'learning_rate': 6.707431796801506e-06, 'epoch': 0.54}\n",
      "{'loss': 0.2874, 'grad_norm': 11.958928108215332, 'learning_rate': 6.613358419567263e-06, 'epoch': 0.55}\n",
      "{'loss': 0.1683, 'grad_norm': 5.746481895446777, 'learning_rate': 6.5192850423330205e-06, 'epoch': 0.56}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification, \n",
    "    Trainer, \n",
    "    TrainingArguments,\n",
    "    BertTokenizer,\n",
    "    BertForSequenceClassification\n",
    ")\n",
    "from datasets import Dataset, load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gradio as gr\n",
    "import gdown\n",
    "import os\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# Updated tone categories \n",
    "TONE_CATEGORIES = [\n",
    "    'Technical / Informative',\n",
    "    'Enthusiastic / Inspirational',\n",
    "    'Casual / Conversational',\n",
    "    'Professional / Neutral',\n",
    "    'Promotional / Persuasive'\n",
    "]\n",
    "\n",
    "def extract_text_from_image(image) -> str:\n",
    "    \"\"\"\n",
    "    Extract text from an uploaded image using OCR\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if isinstance(image, str):\n",
    "            image = Image.open(image)\n",
    "        \n",
    "        if image.mode != 'RGB':\n",
    "            image = image.convert('RGB')\n",
    "            \n",
    "        extracted_text = pytesseract.image_to_string(image)\n",
    "        return extracted_text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error in text extraction: {str(e)}\")\n",
    "        return \"\"\n",
    "\n",
    "def download_and_load_dataset():\n",
    "    \"\"\"\n",
    "    Download the dataset from Google Drive and load it into a pandas DataFrame\n",
    "    \"\"\"\n",
    "    # Google Drive file ID from the shared link\n",
    "    file_id = '1-7jNMWQQkBziKqYnpDOfjkNg-mmCtRtd'\n",
    "    output_path = 'website_tones.parquet'\n",
    "    \n",
    "    # Download the file if it doesn't exist\n",
    "    if not os.path.exists(output_path):\n",
    "        url = f'https://drive.google.com/uc?id={file_id}'\n",
    "        gdown.download(url, output_path, quiet=False)\n",
    "    \n",
    "    # Read the parquet file\n",
    "    df = pd.read_parquet(output_path)\n",
    "    return df\n",
    "\n",
    "class ToneAnalyzer:\n",
    "    def __init__(self, model_name=\"xlm-roberta-base\", num_labels=len(TONE_CATEGORIES)):\n",
    "        \"\"\"\n",
    "        Initialize the ToneAnalyzer with XLM-RoBERTa model\n",
    "        \"\"\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels=num_labels\n",
    "        )\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "        self.tone_categories = TONE_CATEGORIES\n",
    "\n",
    "    def prepare_dataset(self, texts, labels=None):\n",
    "        \"\"\"Prepare dataset for training or inference\"\"\"\n",
    "        encodings = self.tokenizer(\n",
    "            texts,\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=512,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        if labels is not None:\n",
    "            # Convert string labels to numerical indices\n",
    "            label_map = {cat: idx for idx, cat in enumerate(self.tone_categories)}\n",
    "            numeric_labels = [label_map[label] for label in labels]\n",
    "            \n",
    "            dataset = Dataset.from_dict({\n",
    "                'input_ids': encodings['input_ids'],\n",
    "                'attention_mask': encodings['attention_mask'],\n",
    "                'labels': numeric_labels\n",
    "            })\n",
    "        else:\n",
    "            dataset = Dataset.from_dict({\n",
    "                'input_ids': encodings['input_ids'],\n",
    "                'attention_mask': encodings['attention_mask'],\n",
    "            })\n",
    "        \n",
    "        return dataset\n",
    "\n",
    "    def fine_tune(self, train_texts, train_labels, validation_texts=None, validation_labels=None,\n",
    "                 batch_size=8, num_epochs=1, learning_rate=2e-5):\n",
    "        \"\"\"Fine-tune the model on the provided dataset\"\"\"\n",
    "        print(\"Preparing training dataset...\")\n",
    "        train_dataset = self.prepare_dataset(train_texts, train_labels)\n",
    "        \n",
    "        if validation_texts is not None and validation_labels is not None:\n",
    "            print(\"Preparing validation dataset...\")\n",
    "            validation_dataset = self.prepare_dataset(validation_texts, validation_labels)\n",
    "        else:\n",
    "            print(\"Splitting into train/validation sets...\")\n",
    "            train_indices, val_indices = train_test_split(\n",
    "                range(len(train_dataset)), \n",
    "                test_size=0.2, \n",
    "                random_state=42\n",
    "            )\n",
    "            validation_dataset = train_dataset.select(val_indices)\n",
    "            train_dataset = train_dataset.select(train_indices)\n",
    "\n",
    "        print(\"Setting up training arguments...\")\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=\"./tone_analyzer_results\",\n",
    "            num_train_epochs=num_epochs,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            per_device_eval_batch_size=batch_size,\n",
    "            warmup_steps=500,\n",
    "            weight_decay=0.01,\n",
    "            logging_dir=\"./tone_analyzer_logs\",\n",
    "            logging_steps=50,\n",
    "            learning_rate=learning_rate,\n",
    "            evaluation_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            load_best_model_at_end=True,\n",
    "            report_to=\"none\"\n",
    "        )\n",
    "\n",
    "        print(\"Starting training...\")\n",
    "        trainer = Trainer(\n",
    "            model=self.model,\n",
    "            args=training_args,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=validation_dataset\n",
    "        )\n",
    "\n",
    "        trainer.train()\n",
    "        \n",
    "        print(\"Saving fine-tuned model...\")\n",
    "        self.model.save_pretrained(\"./tone_analyzer_finetuned\")\n",
    "        self.tokenizer.save_pretrained(\"./tone_analyzer_finetuned\")\n",
    "        print(\"Fine-tuning complete!\")\n",
    "\n",
    "    def predict_single(self, text):\n",
    "        \"\"\"Predict tone for a single text input\"\"\"\n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=512,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(self.device)\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "            probabilities = torch.softmax(outputs.logits, dim=1)[0]\n",
    "\n",
    "        top_tone_index = torch.argmax(probabilities).item()\n",
    "        return self.tone_categories[top_tone_index]\n",
    "\n",
    "class SentimentAnalyzer:\n",
    "    def __init__(self, model_name=\"bert-base-uncased\", num_labels=3):\n",
    "        \"\"\"\n",
    "        Initialize the SentimentAnalyzer with BERT model\n",
    "        \"\"\"\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "        self.model = BertForSequenceClassification.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels=num_labels\n",
    "        )\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "        self.sentiment_labels = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "    def prepare_dataset(self, texts, labels=None):\n",
    "        \"\"\"Prepare dataset for training or inference\"\"\"\n",
    "        encodings = self.tokenizer(\n",
    "            texts,\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=512,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        if labels is not None:\n",
    "            dataset = Dataset.from_dict({\n",
    "                'input_ids': encodings['input_ids'],\n",
    "                'attention_mask': encodings['attention_mask'],\n",
    "                'labels': labels\n",
    "            })\n",
    "        else:\n",
    "            dataset = Dataset.from_dict({\n",
    "                'input_ids': encodings['input_ids'],\n",
    "                'attention_mask': encodings['attention_mask'],\n",
    "            })\n",
    "        \n",
    "        return dataset\n",
    "\n",
    "    def fine_tune(self, num_epochs=1, learning_rate=1e-5):\n",
    "        \"\"\"\n",
    "        Fine-tune the model on the IMDB dataset\n",
    "        \"\"\"\n",
    "        # Load IMDB dataset\n",
    "        imdb_dataset = load_dataset('imdb')\n",
    "        \n",
    "        # Prepare train and validation datasets\n",
    "        train_texts = imdb_dataset['train']['text']\n",
    "        train_labels = [1 if label == 1 else 0 for label in imdb_dataset['train']['label']]\n",
    "        \n",
    "        val_texts = imdb_dataset['test']['text']\n",
    "        val_labels = [1 if label == 1 else 0 for label in imdb_dataset['test']['label']]\n",
    "        \n",
    "        train_dataset = self.prepare_dataset(train_texts, train_labels)\n",
    "        val_dataset = self.prepare_dataset(val_texts, val_labels)\n",
    "\n",
    "        # Training arguments\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=\"./sentiment_analyzer_results\",\n",
    "            num_train_epochs=num_epochs,\n",
    "            per_device_train_batch_size=8,\n",
    "            per_device_eval_batch_size=8,\n",
    "            warmup_steps=500,\n",
    "            weight_decay=0.01,\n",
    "            logging_dir=\"./sentiment_analyzer_logs\",\n",
    "            logging_steps=50,\n",
    "            learning_rate=learning_rate,\n",
    "            evaluation_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            load_best_model_at_end=True,\n",
    "            report_to=\"none\"\n",
    "        )\n",
    "\n",
    "        # Initialize Trainer\n",
    "        trainer = Trainer(\n",
    "            model=self.model,\n",
    "            args=training_args,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=val_dataset\n",
    "        )\n",
    "\n",
    "        # Train the model\n",
    "        trainer.train()\n",
    "\n",
    "        # Save the fine-tuned model\n",
    "        self.model.save_pretrained(\"./sentiment_analyzer_finetuned\")\n",
    "        self.tokenizer.save_pretrained(\"./sentiment_analyzer_finetuned\")\n",
    "        print(\"Fine-tuning complete!\")\n",
    "\n",
    "    def predict_sentiment(self, text):\n",
    "        \"\"\"Predict sentiment for a single text input\"\"\"\n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=512,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(self.device)\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "            predictions = torch.softmax(outputs.logits, dim=1)\n",
    "            predicted_class = torch.argmax(predictions, dim=1).item()\n",
    "\n",
    "        return self.sentiment_labels[predicted_class]\n",
    "\n",
    "def train_models():\n",
    "    \"\"\"Train both tone and sentiment models\"\"\"\n",
    "    # Train Tone Analyzer\n",
    "    print(\"Downloading and loading tone dataset...\")\n",
    "    df = download_and_load_dataset()\n",
    "    \n",
    "    print(\"Initializing Tone Analyzer...\")\n",
    "    tone_analyzer = ToneAnalyzer()\n",
    "    \n",
    "    print(\"Starting tone fine-tuning process...\")\n",
    "    tone_analyzer.fine_tune(\n",
    "        train_texts=df['sentences'].tolist(),\n",
    "        train_labels=df['tone_heuristic'].tolist(),\n",
    "        batch_size=8,\n",
    "        num_epochs=1,\n",
    "        learning_rate=2e-5\n",
    "    )\n",
    "    \n",
    "    # Train Sentiment Analyzer\n",
    "    print(\"Initializing Sentiment Analyzer...\")\n",
    "    sentiment_analyzer = SentimentAnalyzer()\n",
    "    \n",
    "    print(\"Starting sentiment fine-tuning process...\")\n",
    "    sentiment_analyzer.fine_tune()\n",
    "\n",
    "def create_gradio_interface():\n",
    "    \"\"\"Create and launch the Gradio interface with conditional analysis\"\"\"\n",
    "    def analyze_content(text_input, image_input):\n",
    "        pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "        # Initialize the analyzers with fine-tuned models\n",
    "        tone_analyzer = ToneAnalyzer(model_name=\"./tone_analyzer_finetuned\")\n",
    "        sentiment_analyzer = SentimentAnalyzer(model_name=\"./sentiment_analyzer_finetuned\")\n",
    "\n",
    "        # Handling text input scenario\n",
    "        if text_input and not image_input:\n",
    "            # Only perform sentiment analysis for text input\n",
    "            sentiment = sentiment_analyzer.predict_sentiment(text_input.strip())\n",
    "            return f\"Sentiment: {sentiment}\"\n",
    "\n",
    "        # Handling image input scenario\n",
    "        elif image_input and not text_input:\n",
    "            try:\n",
    "                # Extract text from the image\n",
    "                extracted_text = extract_text_from_image(image_input)\n",
    "                \n",
    "                if not extracted_text:\n",
    "                    return \"No text could be extracted from the image.\"\n",
    "                \n",
    "                # Only predict tone for image\n",
    "                tone = tone_analyzer.predict_single(extracted_text)\n",
    "                return f\"Detected Tone: {tone}\"\n",
    "            \n",
    "            except Exception as e:\n",
    "                return f\"Error processing image: {str(e)}\"\n",
    "\n",
    "        # Handling case where both or neither are provided\n",
    "        elif not text_input and not image_input:\n",
    "            return \"Please provide either text or an image to analyze.\"\n",
    "        else:\n",
    "            return \"Please provide either text or an image, but not both simultaneously.\"\n",
    "\n",
    "    iface = gr.Interface(\n",
    "        fn=analyze_content,\n",
    "        inputs=[\n",
    "            gr.Textbox(\n",
    "                lines=5,\n",
    "                placeholder=\"Enter text for sentiment analysis...\",\n",
    "                label=\"Input Text (Optional)\"\n",
    "            ),\n",
    "            gr.Image(\n",
    "                type=\"pil\",\n",
    "                label=\"Upload Image for Tone Detection (Optional)\"\n",
    "            )\n",
    "        ],\n",
    "        outputs=[\n",
    "            gr.Textbox(\n",
    "                label=\"Analysis Result\",\n",
    "                lines=3\n",
    "            )\n",
    "        ],\n",
    "        title=\"Conditional Sentiment & Tone Analyzer\",\n",
    "        description=\"Analyze sentiment for text or detect tone from images.\",\n",
    "        examples=[\n",
    "            [\"This is a great product that solves many problems.\", None],\n",
    "            [None, \"path/to/sample/image.jpg\"]  # Replace with actual example image path\n",
    "        ]\n",
    "    )\n",
    "    return iface\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # First, train the models\n",
    "    print(\"Starting the training process...\")\n",
    "    train_models()\n",
    "    \n",
    "    # Then launch the Gradio interface\n",
    "    print(\"Launching Gradio interface...\")\n",
    "    iface = create_gradio_interface()\n",
    "    iface.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DevAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
